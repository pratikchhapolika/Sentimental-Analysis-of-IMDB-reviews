{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('labeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('testData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabeled_train = pd.read_csv('unlabeledTrainData.tsv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "unlabeled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordList(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "                \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, tokenizer):\n",
    "    # using nltk tokenizer to split paragraphs into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    sentence = []\n",
    "    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentence.append(review_to_wordList(raw_sentence))\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again.',\n",
       " u'Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent.',\n",
       " u'Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released.',\n",
       " u\"Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring.\",\n",
       " u'Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord.',\n",
       " u'Why he wants MJ dead so bad is beyond me.',\n",
       " u'Because MJ overheard his plans?',\n",
       " u\"Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence.\",\n",
       " u'Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people).',\n",
       " u'If not, then stay away.',\n",
       " u\"It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl!\",\n",
       " u'Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty?',\n",
       " u\"Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact.\",\n",
       " u'He is either an extremely nice but stupid guy or one of the most sickest liars.',\n",
       " u'I hope he is not the latter.\"']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(BeautifulSoup(train['review'][0]).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.archive.org/details/LovefromaStranger\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.loosechangeguide.com/LooseChangeGuide.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.msnbc.msn.com/id/4972055/site/newsweek/\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:219: UserWarning: \"..\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n",
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.youtube.com/watch?v=a0KSqelmgN8\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/yash/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://jake-weird.blogspot.com/2007/08/beneath.html\"\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review.decode('utf8'), tokenizer)\n",
    "\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review.decode('utf8'), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795538\n"
     ]
    }
   ],
   "source": [
    "print len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yash/anaconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "2017-01-07 18:05:03,862 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-01-07 18:05:04,087 : INFO : collecting all words and their counts\n",
      "2017-01-07 18:05:04,088 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-07 18:05:04,264 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 17776 word types\n",
      "2017-01-07 18:05:04,347 : INFO : PROGRESS: at sentence #20000, processed 451887 words, keeping 24948 word types\n",
      "2017-01-07 18:05:04,421 : INFO : PROGRESS: at sentence #30000, processed 671310 words, keeping 30034 word types\n",
      "2017-01-07 18:05:04,499 : INFO : PROGRESS: at sentence #40000, processed 897810 words, keeping 34348 word types\n",
      "2017-01-07 18:05:04,593 : INFO : PROGRESS: at sentence #50000, processed 1116958 words, keeping 37761 word types\n",
      "2017-01-07 18:05:04,678 : INFO : PROGRESS: at sentence #60000, processed 1338399 words, keeping 40723 word types\n",
      "2017-01-07 18:05:04,841 : INFO : PROGRESS: at sentence #70000, processed 1561573 words, keeping 43333 word types\n",
      "2017-01-07 18:05:04,918 : INFO : PROGRESS: at sentence #80000, processed 1780880 words, keeping 45714 word types\n",
      "2017-01-07 18:05:04,994 : INFO : PROGRESS: at sentence #90000, processed 2004989 words, keeping 48135 word types\n",
      "2017-01-07 18:05:05,106 : INFO : PROGRESS: at sentence #100000, processed 2226945 words, keeping 50207 word types\n",
      "2017-01-07 18:05:05,181 : INFO : PROGRESS: at sentence #110000, processed 2446559 words, keeping 52081 word types\n",
      "2017-01-07 18:05:05,256 : INFO : PROGRESS: at sentence #120000, processed 2668754 words, keeping 54119 word types\n",
      "2017-01-07 18:05:05,361 : INFO : PROGRESS: at sentence #130000, processed 2894274 words, keeping 55847 word types\n",
      "2017-01-07 18:05:05,450 : INFO : PROGRESS: at sentence #140000, processed 3106976 words, keeping 57346 word types\n",
      "2017-01-07 18:05:05,557 : INFO : PROGRESS: at sentence #150000, processed 3332598 words, keeping 59055 word types\n",
      "2017-01-07 18:05:05,655 : INFO : PROGRESS: at sentence #160000, processed 3555286 words, keeping 60617 word types\n",
      "2017-01-07 18:05:05,752 : INFO : PROGRESS: at sentence #170000, processed 3778626 words, keeping 62077 word types\n",
      "2017-01-07 18:05:05,849 : INFO : PROGRESS: at sentence #180000, processed 3999207 words, keeping 63496 word types\n",
      "2017-01-07 18:05:05,925 : INFO : PROGRESS: at sentence #190000, processed 4224420 words, keeping 64794 word types\n",
      "2017-01-07 18:05:06,047 : INFO : PROGRESS: at sentence #200000, processed 4448574 words, keeping 66087 word types\n",
      "2017-01-07 18:05:06,139 : INFO : PROGRESS: at sentence #210000, processed 4669938 words, keeping 67390 word types\n",
      "2017-01-07 18:05:06,222 : INFO : PROGRESS: at sentence #220000, processed 4894939 words, keeping 68697 word types\n",
      "2017-01-07 18:05:06,315 : INFO : PROGRESS: at sentence #230000, processed 5117502 words, keeping 69958 word types\n",
      "2017-01-07 18:05:06,429 : INFO : PROGRESS: at sentence #240000, processed 5345007 words, keeping 71167 word types\n",
      "2017-01-07 18:05:06,523 : INFO : PROGRESS: at sentence #250000, processed 5559122 words, keeping 72351 word types\n",
      "2017-01-07 18:05:06,617 : INFO : PROGRESS: at sentence #260000, processed 5779086 words, keeping 73478 word types\n",
      "2017-01-07 18:05:06,713 : INFO : PROGRESS: at sentence #270000, processed 6000375 words, keeping 74767 word types\n",
      "2017-01-07 18:05:06,829 : INFO : PROGRESS: at sentence #280000, processed 6226254 words, keeping 76369 word types\n",
      "2017-01-07 18:05:06,921 : INFO : PROGRESS: at sentence #290000, processed 6449414 words, keeping 77839 word types\n",
      "2017-01-07 18:05:07,030 : INFO : PROGRESS: at sentence #300000, processed 6674015 words, keeping 79171 word types\n",
      "2017-01-07 18:05:07,114 : INFO : PROGRESS: at sentence #310000, processed 6899329 words, keeping 80480 word types\n",
      "2017-01-07 18:05:07,193 : INFO : PROGRESS: at sentence #320000, processed 7124216 words, keeping 81808 word types\n",
      "2017-01-07 18:05:07,267 : INFO : PROGRESS: at sentence #330000, processed 7345958 words, keeping 83030 word types\n",
      "2017-01-07 18:05:07,343 : INFO : PROGRESS: at sentence #340000, processed 7575470 words, keeping 84280 word types\n",
      "2017-01-07 18:05:07,417 : INFO : PROGRESS: at sentence #350000, processed 7798740 words, keeping 85425 word types\n",
      "2017-01-07 18:05:07,491 : INFO : PROGRESS: at sentence #360000, processed 8019345 words, keeping 86596 word types\n",
      "2017-01-07 18:05:07,593 : INFO : PROGRESS: at sentence #370000, processed 8246537 words, keeping 87708 word types\n",
      "2017-01-07 18:05:07,695 : INFO : PROGRESS: at sentence #380000, processed 8471679 words, keeping 88878 word types\n",
      "2017-01-07 18:05:07,789 : INFO : PROGRESS: at sentence #390000, processed 8701410 words, keeping 89907 word types\n",
      "2017-01-07 18:05:07,887 : INFO : PROGRESS: at sentence #400000, processed 8924359 words, keeping 90916 word types\n",
      "2017-01-07 18:05:07,981 : INFO : PROGRESS: at sentence #410000, processed 9145709 words, keeping 91880 word types\n",
      "2017-01-07 18:05:08,056 : INFO : PROGRESS: at sentence #420000, processed 9366777 words, keeping 92912 word types\n",
      "2017-01-07 18:05:08,155 : INFO : PROGRESS: at sentence #430000, processed 9594314 words, keeping 93932 word types\n",
      "2017-01-07 18:05:08,254 : INFO : PROGRESS: at sentence #440000, processed 9821067 words, keeping 94906 word types\n",
      "2017-01-07 18:05:08,353 : INFO : PROGRESS: at sentence #450000, processed 10044829 words, keeping 96036 word types\n",
      "2017-01-07 18:05:08,452 : INFO : PROGRESS: at sentence #460000, processed 10277589 words, keeping 97088 word types\n",
      "2017-01-07 18:05:08,552 : INFO : PROGRESS: at sentence #470000, processed 10505514 words, keeping 97933 word types\n",
      "2017-01-07 18:05:08,630 : INFO : PROGRESS: at sentence #480000, processed 10725890 words, keeping 98862 word types\n",
      "2017-01-07 18:05:08,709 : INFO : PROGRESS: at sentence #490000, processed 10952634 words, keeping 99871 word types\n",
      "2017-01-07 18:05:08,793 : INFO : PROGRESS: at sentence #500000, processed 11174290 words, keeping 100765 word types\n",
      "2017-01-07 18:05:08,871 : INFO : PROGRESS: at sentence #510000, processed 11399565 words, keeping 101699 word types\n",
      "2017-01-07 18:05:08,949 : INFO : PROGRESS: at sentence #520000, processed 11622901 words, keeping 102598 word types\n",
      "2017-01-07 18:05:09,026 : INFO : PROGRESS: at sentence #530000, processed 11847299 words, keeping 103400 word types\n",
      "2017-01-07 18:05:09,118 : INFO : PROGRESS: at sentence #540000, processed 12071914 words, keeping 104265 word types\n",
      "2017-01-07 18:05:09,222 : INFO : PROGRESS: at sentence #550000, processed 12297452 words, keeping 105133 word types\n",
      "2017-01-07 18:05:09,321 : INFO : PROGRESS: at sentence #560000, processed 12518723 words, keeping 105997 word types\n",
      "2017-01-07 18:05:09,395 : INFO : PROGRESS: at sentence #570000, processed 12747772 words, keeping 106787 word types\n",
      "2017-01-07 18:05:09,472 : INFO : PROGRESS: at sentence #580000, processed 12969256 words, keeping 107664 word types\n",
      "2017-01-07 18:05:09,551 : INFO : PROGRESS: at sentence #590000, processed 13194781 words, keeping 108500 word types\n",
      "2017-01-07 18:05:09,629 : INFO : PROGRESS: at sentence #600000, processed 13416979 words, keeping 109217 word types\n",
      "2017-01-07 18:05:09,693 : INFO : PROGRESS: at sentence #610000, processed 13638002 words, keeping 110091 word types\n",
      "2017-01-07 18:05:09,803 : INFO : PROGRESS: at sentence #620000, processed 13864300 words, keeping 110836 word types\n",
      "2017-01-07 18:05:09,891 : INFO : PROGRESS: at sentence #630000, processed 14088586 words, keeping 111609 word types\n",
      "2017-01-07 18:05:09,967 : INFO : PROGRESS: at sentence #640000, processed 14309369 words, keeping 112415 word types\n",
      "2017-01-07 18:05:10,050 : INFO : PROGRESS: at sentence #650000, processed 14535125 words, keeping 113195 word types\n",
      "2017-01-07 18:05:10,130 : INFO : PROGRESS: at sentence #660000, processed 14757903 words, keeping 113944 word types\n",
      "2017-01-07 18:05:10,206 : INFO : PROGRESS: at sentence #670000, processed 14981287 words, keeping 114642 word types\n",
      "2017-01-07 18:05:10,283 : INFO : PROGRESS: at sentence #680000, processed 15206119 words, keeping 115353 word types\n",
      "2017-01-07 18:05:10,360 : INFO : PROGRESS: at sentence #690000, processed 15428312 words, keeping 116130 word types\n",
      "2017-01-07 18:05:10,438 : INFO : PROGRESS: at sentence #700000, processed 15657015 words, keeping 116943 word types\n",
      "2017-01-07 18:05:10,526 : INFO : PROGRESS: at sentence #710000, processed 15879999 words, keeping 117596 word types\n",
      "2017-01-07 18:05:10,606 : INFO : PROGRESS: at sentence #720000, processed 16105286 words, keeping 118221 word types\n",
      "2017-01-07 18:05:10,688 : INFO : PROGRESS: at sentence #730000, processed 16331667 words, keeping 118954 word types\n",
      "2017-01-07 18:05:10,763 : INFO : PROGRESS: at sentence #740000, processed 16552700 words, keeping 119668 word types\n",
      "2017-01-07 18:05:10,844 : INFO : PROGRESS: at sentence #750000, processed 16771027 words, keeping 120295 word types\n",
      "2017-01-07 18:05:10,918 : INFO : PROGRESS: at sentence #760000, processed 16990419 words, keeping 120930 word types\n",
      "2017-01-07 18:05:10,999 : INFO : PROGRESS: at sentence #770000, processed 17217556 words, keeping 121703 word types\n",
      "2017-01-07 18:05:11,079 : INFO : PROGRESS: at sentence #780000, processed 17447702 words, keeping 122402 word types\n",
      "2017-01-07 18:05:11,158 : INFO : PROGRESS: at sentence #790000, processed 17674778 words, keeping 123066 word types\n",
      "2017-01-07 18:05:11,202 : INFO : collected 123504 word types from a corpus of 17797876 raw words and 795538 sentences\n",
      "2017-01-07 18:05:11,203 : INFO : Loading a fresh vocabulary\n",
      "2017-01-07 18:05:11,346 : INFO : min_count=40 retains 16490 unique words (13% of original 123504, drops 107014)\n",
      "2017-01-07 18:05:11,346 : INFO : min_count=40 leaves 17238737 word corpus (96% of original 17797876, drops 559139)\n",
      "2017-01-07 18:05:11,526 : INFO : deleting the raw counts dictionary of 123504 items\n",
      "2017-01-07 18:05:11,571 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2017-01-07 18:05:11,572 : INFO : downsampling leaves estimated 12749491 word corpus (74.0% of prior 17238737)\n",
      "2017-01-07 18:05:11,574 : INFO : estimated required memory for 16490 words and 300 dimensions: 47821000 bytes\n",
      "2017-01-07 18:05:11,670 : INFO : resetting layer weights\n",
      "2017-01-07 18:05:11,972 : INFO : training model with 4 workers on 16490 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-01-07 18:05:11,973 : INFO : expecting 795538 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-07 18:05:13,022 : INFO : PROGRESS: at 0.65% examples, 410311 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:14,034 : INFO : PROGRESS: at 1.43% examples, 448410 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:15,043 : INFO : PROGRESS: at 2.23% examples, 466891 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:16,052 : INFO : PROGRESS: at 3.05% examples, 477840 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:17,055 : INFO : PROGRESS: at 3.75% examples, 470635 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:18,071 : INFO : PROGRESS: at 4.46% examples, 466199 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:19,073 : INFO : PROGRESS: at 5.16% examples, 462860 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:20,100 : INFO : PROGRESS: at 5.84% examples, 457971 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:21,128 : INFO : PROGRESS: at 6.66% examples, 463291 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:22,122 : INFO : PROGRESS: at 7.44% examples, 466785 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:23,130 : INFO : PROGRESS: at 8.24% examples, 470090 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:24,149 : INFO : PROGRESS: at 9.04% examples, 473029 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-07 18:05:25,143 : INFO : PROGRESS: at 9.81% examples, 474856 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:26,157 : INFO : PROGRESS: at 10.61% examples, 476656 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:27,164 : INFO : PROGRESS: at 11.39% examples, 478002 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:28,169 : INFO : PROGRESS: at 12.17% examples, 479673 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:29,173 : INFO : PROGRESS: at 12.96% examples, 480762 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:30,198 : INFO : PROGRESS: at 13.74% examples, 481526 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:31,192 : INFO : PROGRESS: at 14.52% examples, 482378 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:32,196 : INFO : PROGRESS: at 15.30% examples, 482891 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-07 18:05:33,201 : INFO : PROGRESS: at 16.07% examples, 483211 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:34,214 : INFO : PROGRESS: at 16.86% examples, 483725 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:35,225 : INFO : PROGRESS: at 17.46% examples, 479303 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:36,226 : INFO : PROGRESS: at 18.11% examples, 476630 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:37,230 : INFO : PROGRESS: at 18.91% examples, 477805 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:38,233 : INFO : PROGRESS: at 19.69% examples, 478609 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:39,238 : INFO : PROGRESS: at 20.48% examples, 479601 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:40,252 : INFO : PROGRESS: at 21.27% examples, 480087 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:41,265 : INFO : PROGRESS: at 21.88% examples, 476669 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:42,319 : INFO : PROGRESS: at 22.55% examples, 474029 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:43,335 : INFO : PROGRESS: at 23.24% examples, 472737 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:44,336 : INFO : PROGRESS: at 24.00% examples, 472759 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:45,339 : INFO : PROGRESS: at 24.73% examples, 472496 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:46,357 : INFO : PROGRESS: at 25.50% examples, 472652 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:47,359 : INFO : PROGRESS: at 26.25% examples, 472791 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-07 18:05:48,373 : INFO : PROGRESS: at 26.98% examples, 472165 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:49,385 : INFO : PROGRESS: at 27.56% examples, 469346 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:50,392 : INFO : PROGRESS: at 28.33% examples, 469887 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:51,412 : INFO : PROGRESS: at 29.11% examples, 470430 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:52,427 : INFO : PROGRESS: at 29.89% examples, 471001 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:53,446 : INFO : PROGRESS: at 30.68% examples, 471527 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:54,444 : INFO : PROGRESS: at 31.41% examples, 471533 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:55,445 : INFO : PROGRESS: at 32.12% examples, 471210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:05:56,446 : INFO : PROGRESS: at 32.87% examples, 471382 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:57,469 : INFO : PROGRESS: at 33.62% examples, 471315 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:05:58,481 : INFO : PROGRESS: at 34.40% examples, 471835 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-07 18:05:59,498 : INFO : PROGRESS: at 35.16% examples, 472075 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:00,487 : INFO : PROGRESS: at 35.83% examples, 471181 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:01,489 : INFO : PROGRESS: at 36.57% examples, 471035 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-07 18:06:02,498 : INFO : PROGRESS: at 37.35% examples, 471532 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:03,529 : INFO : PROGRESS: at 38.09% examples, 471259 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:04,544 : INFO : PROGRESS: at 38.60% examples, 468419 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:05,567 : INFO : PROGRESS: at 39.11% examples, 465360 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:06,577 : INFO : PROGRESS: at 39.79% examples, 464872 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:07,585 : INFO : PROGRESS: at 40.56% examples, 465315 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:08,600 : INFO : PROGRESS: at 41.11% examples, 463158 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:09,603 : INFO : PROGRESS: at 41.58% examples, 460181 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:10,605 : INFO : PROGRESS: at 42.23% examples, 459395 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:11,619 : INFO : PROGRESS: at 42.70% examples, 456518 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:12,630 : INFO : PROGRESS: at 43.20% examples, 454279 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-07 18:06:13,641 : INFO : PROGRESS: at 43.98% examples, 454632 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-07 18:06:14,658 : INFO : PROGRESS: at 44.68% examples, 454441 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-07 18:06:15,649 : INFO : PROGRESS: at 45.45% examples, 455004 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:16,657 : INFO : PROGRESS: at 46.24% examples, 455657 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:17,676 : INFO : PROGRESS: at 47.02% examples, 456080 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:18,678 : INFO : PROGRESS: at 47.79% examples, 456639 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:19,679 : INFO : PROGRESS: at 48.46% examples, 456217 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:20,681 : INFO : PROGRESS: at 49.24% examples, 456852 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:21,690 : INFO : PROGRESS: at 50.02% examples, 457439 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:22,693 : INFO : PROGRESS: at 50.81% examples, 458011 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-07 18:06:23,698 : INFO : PROGRESS: at 51.58% examples, 458569 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:24,704 : INFO : PROGRESS: at 52.36% examples, 459115 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:25,707 : INFO : PROGRESS: at 53.13% examples, 459464 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:26,721 : INFO : PROGRESS: at 53.85% examples, 459449 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-07 18:06:27,731 : INFO : PROGRESS: at 54.66% examples, 460120 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:28,743 : INFO : PROGRESS: at 55.44% examples, 460576 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:29,762 : INFO : PROGRESS: at 56.23% examples, 460981 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:30,776 : INFO : PROGRESS: at 57.02% examples, 461500 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:31,793 : INFO : PROGRESS: at 57.78% examples, 461776 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:32,790 : INFO : PROGRESS: at 58.56% examples, 462119 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:33,790 : INFO : PROGRESS: at 59.34% examples, 462497 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:34,795 : INFO : PROGRESS: at 60.10% examples, 462849 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:35,812 : INFO : PROGRESS: at 60.89% examples, 463275 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:36,808 : INFO : PROGRESS: at 61.68% examples, 463664 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:37,821 : INFO : PROGRESS: at 62.47% examples, 464027 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:38,845 : INFO : PROGRESS: at 63.26% examples, 464322 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:39,854 : INFO : PROGRESS: at 64.02% examples, 464440 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:40,864 : INFO : PROGRESS: at 64.82% examples, 464881 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:41,873 : INFO : PROGRESS: at 65.60% examples, 465144 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:42,874 : INFO : PROGRESS: at 66.38% examples, 465445 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:43,880 : INFO : PROGRESS: at 67.17% examples, 465794 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:44,888 : INFO : PROGRESS: at 67.95% examples, 466129 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:45,893 : INFO : PROGRESS: at 68.73% examples, 466472 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:46,895 : INFO : PROGRESS: at 69.45% examples, 466369 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:47,898 : INFO : PROGRESS: at 70.17% examples, 466343 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:48,916 : INFO : PROGRESS: at 70.95% examples, 466601 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:49,930 : INFO : PROGRESS: at 71.74% examples, 466963 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:50,952 : INFO : PROGRESS: at 72.52% examples, 467191 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:51,963 : INFO : PROGRESS: at 73.28% examples, 467336 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:52,981 : INFO : PROGRESS: at 74.07% examples, 467631 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:53,990 : INFO : PROGRESS: at 74.85% examples, 467931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:54,989 : INFO : PROGRESS: at 75.63% examples, 468185 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:55,998 : INFO : PROGRESS: at 76.42% examples, 468454 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:57,012 : INFO : PROGRESS: at 77.20% examples, 468697 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:06:58,022 : INFO : PROGRESS: at 77.98% examples, 468947 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:06:59,040 : INFO : PROGRESS: at 78.78% examples, 469237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:00,047 : INFO : PROGRESS: at 79.58% examples, 469567 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:01,066 : INFO : PROGRESS: at 80.36% examples, 469810 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:02,066 : INFO : PROGRESS: at 81.14% examples, 470046 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:03,068 : INFO : PROGRESS: at 81.94% examples, 470312 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:04,075 : INFO : PROGRESS: at 82.73% examples, 470560 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:05,081 : INFO : PROGRESS: at 83.52% examples, 470740 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:06,089 : INFO : PROGRESS: at 84.30% examples, 470965 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:07,097 : INFO : PROGRESS: at 85.09% examples, 471187 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:08,102 : INFO : PROGRESS: at 85.87% examples, 471419 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:09,114 : INFO : PROGRESS: at 86.68% examples, 471619 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:10,127 : INFO : PROGRESS: at 87.46% examples, 471809 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:11,139 : INFO : PROGRESS: at 88.23% examples, 471987 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:12,128 : INFO : PROGRESS: at 89.01% examples, 472222 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:13,129 : INFO : PROGRESS: at 89.78% examples, 472392 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:14,144 : INFO : PROGRESS: at 90.57% examples, 472565 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:15,151 : INFO : PROGRESS: at 91.33% examples, 472702 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:16,165 : INFO : PROGRESS: at 92.11% examples, 472874 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:17,175 : INFO : PROGRESS: at 92.90% examples, 473116 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:18,185 : INFO : PROGRESS: at 93.69% examples, 473299 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-07 18:07:19,208 : INFO : PROGRESS: at 94.42% examples, 473208 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:20,229 : INFO : PROGRESS: at 95.12% examples, 472933 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:21,226 : INFO : PROGRESS: at 95.89% examples, 473066 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:22,238 : INFO : PROGRESS: at 96.65% examples, 473067 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:23,251 : INFO : PROGRESS: at 97.37% examples, 472960 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:24,261 : INFO : PROGRESS: at 98.12% examples, 472969 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:25,272 : INFO : PROGRESS: at 98.91% examples, 473138 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-07 18:07:26,288 : INFO : PROGRESS: at 99.67% examples, 473222 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-07 18:07:26,670 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-07 18:07:26,685 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-07 18:07:26,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-07 18:07:26,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-07 18:07:26,702 : INFO : training on 88989380 raw words (63752365 effective words) took 134.7s, 473321 effective words/s\n",
      "2017-01-07 18:07:26,703 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-07 18:07:26,872 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2017-01-07 18:07:26,873 : INFO : not storing attribute syn0norm\n",
      "2017-01-07 18:07:26,874 : INFO : not storing attribute cum_table\n",
      "2017-01-07 18:07:27,115 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, size=num_features, min_count=min_word_count, \n",
    "                          window=context, sample=downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('man woman child kitchen'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match('india paris england berlin'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'woman', 0.6119527816772461),\n",
       " (u'lady', 0.5812598466873169),\n",
       " (u'lad', 0.5498437881469727),\n",
       " (u'millionaire', 0.5329727530479431),\n",
       " (u'guy', 0.5293763875961304),\n",
       " (u'monk', 0.5229437351226807),\n",
       " (u'men', 0.514629602432251),\n",
       " (u'farmer', 0.5098802447319031),\n",
       " (u'businessman', 0.5018507838249207),\n",
       " (u'soldier', 0.4967585504055023)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'horrible', 0.8846541047096252),\n",
       " (u'atrocious', 0.79456627368927),\n",
       " (u'dreadful', 0.7850203514099121),\n",
       " (u'awful', 0.7802629470825195),\n",
       " (u'horrendous', 0.7797378301620483),\n",
       " (u'horrid', 0.7629272937774658),\n",
       " (u'lousy', 0.7255361080169678),\n",
       " (u'abysmal', 0.7225754261016846),\n",
       " (u'laughable', 0.670087993144989),\n",
       " (u'bad', 0.6683333516120911)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('terrible')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
